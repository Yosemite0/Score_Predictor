{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "020a349f",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89596e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa34d87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Memory Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c770db1",
   "metadata": {},
   "source": [
    "## Loading required data and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b185dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data/updated_over_by_over_data_set.csv')\n",
    "\n",
    "df['season'] = df['season'].astype(str)\n",
    "df['season_year'] = df['season'].apply(lambda x: int(x.split('/')[0]))\n",
    "max_year = 2024\n",
    "df['season_weight'] = np.exp(-0.1 * (max_year - df['season_year']))\n",
    "\n",
    "# Encode teams using LabelEncoder + Embedding\n",
    "team_encoder = LabelEncoder()\n",
    "df['batting_team'] = team_encoder.fit_transform(df['batting_team'])\n",
    "df['bowling_team'] = team_encoder.fit_transform(df['bowling_team'])\n",
    "\n",
    "# Numerical features\n",
    "numerical_features = ['over', 'run_rate', 'req_runrate', 'target_left', 'season_weight']\n",
    "scaler = StandardScaler()\n",
    "numerical_data = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Step 3: Split the dataset into train and test (by match_id)\n",
    "match_ids = df['match_id'].unique()\n",
    "train_match_ids, test_match_ids = train_test_split(match_ids, test_size=0.2, random_state=42)\n",
    "train_df = df[df['match_id'].isin(train_match_ids)].reset_index(drop=True)\n",
    "test_df = df[df['match_id'].isin(test_match_ids)].reset_index(drop=True)\n",
    "\n",
    "# Prepare numerical data for train and test sets\n",
    "train_numerical_data = scaler.transform(train_df[numerical_features])\n",
    "test_numerical_data = scaler.transform(test_df[numerical_features])\n",
    "\n",
    "# Create index mappings for train and test DataFrames\n",
    "train_index_map = {old_idx: new_idx for new_idx, old_idx in enumerate(train_df.index)}\n",
    "test_index_map = {old_idx: new_idx for new_idx, old_idx in enumerate(test_df.index)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc9b45",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723e2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPLDataset(Dataset):\n",
    "    def __init__(self, df, numerical_data, index_map):\n",
    "        self.df = df\n",
    "        self.numerical_data = numerical_data\n",
    "        self.index_map = index_map\n",
    "        self.matches = []\n",
    "        for match_id in df['match_id'].unique():\n",
    "            for inning in [1, 2]:\n",
    "                match_inning = df[(df['match_id'] == match_id) & (df['inning'] == inning)]\n",
    "                if len(match_inning) > 1:\n",
    "                    self.matches.append(match_inning)\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(match) - 1 for match in self.matches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cum_idx = 0\n",
    "        for match in self.matches:\n",
    "            match_len = len(match) - 1\n",
    "            if cum_idx + match_len > idx:\n",
    "                over_idx = idx - cum_idx\n",
    "                current_over = match.iloc[:over_idx + 1]\n",
    "                next_over = match.iloc[over_idx + 1]\n",
    "                break\n",
    "            cum_idx += match_len\n",
    "\n",
    "        # Map the original index to the new index in the split DataFrame\n",
    "        original_idx = current_over.index[-1]\n",
    "        mapped_idx = self.index_map[original_idx]\n",
    "\n",
    "        team1 = torch.tensor(current_over['batting_team'].values[-1], dtype=torch.long)\n",
    "        team2 = torch.tensor(current_over['bowling_team'].values[-1], dtype=torch.long)\n",
    "        num_data = torch.tensor(self.numerical_data[mapped_idx], dtype=torch.float32)\n",
    "        runs = torch.tensor(next_over['total_runs'], dtype=torch.float32)\n",
    "        wickets = torch.tensor(next_over['is_wicket'], dtype=torch.float32)\n",
    "        return team1, team2, num_data, runs, wickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7620d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IPLDataset(train_df, train_numerical_data, train_index_map)\n",
    "test_dataset = IPLDataset(test_df, test_numerical_data, test_index_map)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8781f9b1",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e54a41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define the model architecture\n",
    "class IPLModel(nn.Module):\n",
    "    def __init__(self, num_teams, embedding_dim, numerical_dim, hidden_dim):\n",
    "        super(IPLModel, self).__init__()\n",
    "        self.team1_embedding = nn.Embedding(num_teams, embedding_dim)\n",
    "        self.team2_embedding = nn.Embedding(num_teams, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim * 2 + numerical_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim // 2, batch_first=True)\n",
    "        self.fc2 = nn.Linear(hidden_dim // 2, 8)\n",
    "        self.runs_output = nn.Linear(8, 1)\n",
    "        self.wickets_output = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, team1, team2, num_data):\n",
    "        team1_embed = self.team1_embedding(team1).squeeze(1)\n",
    "        team2_embed = self.team2_embedding(team2).squeeze(1)\n",
    "        x = torch.cat((team1_embed, team2_embed, num_data), dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        x = self.fc2(lstm_out)\n",
    "        x = self.relu(x)\n",
    "        runs = self.runs_output(x).squeeze()\n",
    "        wickets = self.wickets_output(x).squeeze()\n",
    "        wickets = self.relu(wickets)\n",
    "        return runs, wickets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f6411",
   "metadata": {},
   "source": [
    "## Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9062464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalyan-neeraj/Desktop/Smai/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "Train Loss: 28.0482, Test Loss: 21.0750\n",
      "Train Runs MAE: 4.0717, Test Runs MAE: 3.6037\n",
      "Train Wickets MAE: 0.3160, Test Wickets MAE: 0.3097\n",
      "Best model saved with Test Loss: 21.0750\n",
      "Epoch 2/10:\n",
      "Train Loss: 21.1689, Test Loss: 20.6477\n",
      "Train Runs MAE: 3.6113, Test Runs MAE: 3.5632\n",
      "Train Wickets MAE: 0.3128, Test Wickets MAE: 0.3097\n",
      "Best model saved with Test Loss: 20.6477\n",
      "Epoch 3/10:\n",
      "Train Loss: 21.0211, Test Loss: 20.6036\n",
      "Train Runs MAE: 3.5999, Test Runs MAE: 3.6027\n",
      "Train Wickets MAE: 0.3127, Test Wickets MAE: 0.3097\n",
      "Best model saved with Test Loss: 20.6036\n",
      "Epoch 4/10:\n",
      "Train Loss: 20.9386, Test Loss: 20.5642\n",
      "Train Runs MAE: 3.5917, Test Runs MAE: 3.5822\n",
      "Train Wickets MAE: 0.3128, Test Wickets MAE: 0.3097\n",
      "Best model saved with Test Loss: 20.5642\n",
      "Epoch 5/10:\n",
      "Train Loss: 20.8852, Test Loss: 20.4474\n",
      "Train Runs MAE: 3.5880, Test Runs MAE: 3.5647\n",
      "Train Wickets MAE: 0.3128, Test Wickets MAE: 0.3097\n",
      "Best model saved with Test Loss: 20.4474\n",
      "Epoch 6/10:\n",
      "Train Loss: 20.8710, Test Loss: 20.6346\n",
      "Train Runs MAE: 3.5852, Test Runs MAE: 3.6184\n",
      "Train Wickets MAE: 0.3127, Test Wickets MAE: 0.3097\n",
      "Best model saved with Test Loss: 20.6346\n",
      "Epoch 7/10:\n",
      "Train Loss: 20.8307, Test Loss: 20.5217\n",
      "Train Runs MAE: 3.5829, Test Runs MAE: 3.5439\n",
      "Train Wickets MAE: 0.3127, Test Wickets MAE: 0.3097\n",
      "Best model saved with Test Loss: 20.5217\n",
      "Epoch 8/10:\n",
      "Train Loss: 20.7989, Test Loss: 20.5940\n",
      "Train Runs MAE: 3.5784, Test Runs MAE: 3.6221\n",
      "Train Wickets MAE: 0.3127, Test Wickets MAE: 0.3097\n",
      "Best model saved with Test Loss: 20.5940\n",
      "Epoch 9/10:\n",
      "Train Loss: 20.7560, Test Loss: 20.5901\n",
      "Train Runs MAE: 3.5757, Test Runs MAE: 3.5443\n",
      "Train Wickets MAE: 0.3128, Test Wickets MAE: 0.3097\n",
      "Best model saved with Test Loss: 20.5901\n"
     ]
    }
   ],
   "source": [
    "num_teams = len(team_encoder.classes_)\n",
    "model = IPLModel(num_teams=num_teams, embedding_dim=10, numerical_dim=len(numerical_features), hidden_dim=32)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Lists to store metrics for plotting\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_runs_mae = []\n",
    "test_runs_mae = []\n",
    "train_wickets_mae = []\n",
    "test_wickets_mae = []\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_r_mae = 0\n",
    "    train_w_mae = 0\n",
    "    for team1, team2, num_data, runs, wickets in train_loader:\n",
    "        team1, team2, num_data = team1.to(device), team2.to(device), num_data.to(device)\n",
    "        runs, wickets = runs.to(device), wickets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred_runs, pred_wickets = model(team1, team2, num_data)\n",
    "        loss_runs = criterion(pred_runs, runs)\n",
    "        loss_wickets = criterion(pred_wickets, wickets)\n",
    "        loss = loss_runs + loss_wickets\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_r_mae += torch.mean(torch.abs(pred_runs - runs)).item()\n",
    "        train_w_mae += torch.mean(torch.abs(pred_wickets - wickets)).item()\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_runs_mae.append(train_r_mae / len(train_loader))\n",
    "    train_wickets_mae.append(train_w_mae / len(train_loader))\n",
    "\n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_r_mae = 0\n",
    "    test_w_mae = 0\n",
    "    with torch.no_grad():\n",
    "        for team1, team2, num_data, runs, wickets in test_loader:\n",
    "            team1, team2, num_data = team1.to(device), team2.to(device), num_data.to(device)\n",
    "            runs, wickets = runs.to(device), wickets.to(device)\n",
    "\n",
    "            pred_runs, pred_wickets = model(team1, team2, num_data)\n",
    "            loss_runs = criterion(pred_runs, runs)\n",
    "            loss_wickets = criterion(pred_wickets, wickets)\n",
    "            loss = loss_runs + loss_wickets\n",
    "            test_loss += loss.item()\n",
    "            test_r_mae += torch.mean(torch.abs(pred_runs - runs)).item()\n",
    "            test_w_mae += torch.mean(torch.abs(pred_wickets - wickets)).item()\n",
    "\n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "    test_runs_mae.append(test_r_mae / len(test_loader))\n",
    "    test_wickets_mae.append(test_w_mae / len(test_loader))\n",
    "\n",
    "    # Print epoch results\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}\")\n",
    "    print(f\"Train Runs MAE: {train_runs_mae[-1]:.4f}, Test Runs MAE: {test_runs_mae[-1]:.4f}\")\n",
    "    print(f\"Train Wickets MAE: {train_wickets_mae[-1]:.4f}, Test Wickets MAE: {test_wickets_mae[-1]:.4f}\")\n",
    "\n",
    "    best_test_loss = float(\"inf\")\n",
    "    # Save best model\n",
    "    if test_losses[-1] < best_test_loss:\n",
    "        best_test_loss = test_losses[-1]\n",
    "        torch.save(model.state_dict(), 'best_ipl_model.pth')\n",
    "        print(f\"Best model saved with Test Loss: {best_test_loss:.4f}\")\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"CUDA Memory Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")\n",
    "epochs = range(1, num_epochs + 1)\n",
    "# Plot 1: Training vs Testing Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(epochs, test_losses, label='Test Loss', marker='o')\n",
    "plt.title('Training and Testing Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('loss_over_epochs.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: Training vs Testing Runs MAE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_runs_mae, label='Train Runs MAE', marker='o')\n",
    "plt.plot(epochs, test_runs_mae, label='Test Runs MAE', marker='o')\n",
    "plt.title('Training and Testing Runs MAE Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE (Runs)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('runs_mae_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 3: Training vs Testing Wickets MAE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_wickets_mae, label='Train Wickets MAE', marker='o')\n",
    "plt.plot(epochs, test_wickets_mae, label='Test Wickets MAE', marker='o')\n",
    "plt.title('Training and Testing Wickets MAE Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE (Wickets)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('wickets_mae_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Plots saved as 'loss_over_epochs.png', 'runs_mae_over_epochs.png', and 'wickets_mae_over_epochs.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8fa96",
   "metadata": {},
   "source": [
    "## Evaluation and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6459307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Load the best model and show predictions\n",
    "print(\"\\n📥 Loading best model for evaluation...\")\n",
    "model.load_state_dict(torch.load('best_ipl_over_prediction_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "print(\"\\n🎯 Actual vs Predicted on Test Set (first 10 samples):\")\n",
    "num_samples_to_show = 10\n",
    "shown = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for team1, team2, num_data, runs, wickets in test_loader:\n",
    "        team1, team2, num_data = team1.to(device), team2.to(device), num_data.to(device)\n",
    "        runs, wickets = runs.to(device), wickets.to(device)\n",
    "\n",
    "        pred_runs, pred_wickets = model(team1, team2, num_data)\n",
    "\n",
    "        for i in range(len(runs)):\n",
    "            actual_runs = runs[i].item()\n",
    "            predicted_runs = pred_runs[i].item()\n",
    "\n",
    "            actual_wickets = wickets[i].item()\n",
    "            predicted_wickets = pred_wickets[i].item()\n",
    "\n",
    "            print(f\"Sample {shown+1}:\")\n",
    "            print(f\"  Runs    - Actual: {actual_runs:.2f}, Predicted: {predicted_runs:.2f}\")\n",
    "            print(f\"  Wickets - Actual: {actual_wickets:.2f}, Predicted: {predicted_wickets:.2f} (rounded: {int(round(predicted_wickets))})\\n\")\n",
    "\n",
    "            shown += 1\n",
    "            if shown >= num_samples_to_show:\n",
    "                break\n",
    "        if shown >= num_samples_to_show:\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
