{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "020a349f",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89596e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa34d87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Memory Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c770db1",
   "metadata": {},
   "source": [
    "## Loading required data and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b185dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data/updated_over_by_over_data_set.csv')\n",
    "\n",
    "df['season'] = df['season'].astype(str)\n",
    "df['season_year'] = df['season'].apply(lambda x: int(x.split('/')[0]))\n",
    "max_year = 2024\n",
    "df['season_weight'] = np.exp(-0.1 * (max_year - df['season_year']))\n",
    "\n",
    "# Encode teams using LabelEncoder + Embedding\n",
    "team_encoder = LabelEncoder()\n",
    "df['batting_team'] = team_encoder.fit_transform(df['batting_team'])\n",
    "df['bowling_team'] = team_encoder.fit_transform(df['bowling_team'])\n",
    "\n",
    "# Numerical features\n",
    "numerical_features = ['over', 'run_rate', 'req_runrate', 'target_left', 'season_weight']\n",
    "scaler = StandardScaler()\n",
    "numerical_data = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Step 3: Split the dataset into train and test (by match_id)\n",
    "match_ids = df['match_id'].unique()\n",
    "train_match_ids, test_match_ids = train_test_split(match_ids, test_size=0.2, random_state=42)\n",
    "train_df = df[df['match_id'].isin(train_match_ids)].reset_index(drop=True)\n",
    "test_df = df[df['match_id'].isin(test_match_ids)].reset_index(drop=True)\n",
    "\n",
    "# Prepare numerical data for train and test sets\n",
    "train_numerical_data = scaler.transform(train_df[numerical_features])\n",
    "test_numerical_data = scaler.transform(test_df[numerical_features])\n",
    "\n",
    "# Create index mappings for train and test DataFrames\n",
    "train_index_map = {old_idx: new_idx for new_idx, old_idx in enumerate(train_df.index)}\n",
    "test_index_map = {old_idx: new_idx for new_idx, old_idx in enumerate(test_df.index)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc9b45",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "723e2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPLDataset(Dataset):\n",
    "    def __init__(self, df, numerical_data, index_map):\n",
    "        self.df = df\n",
    "        self.numerical_data = numerical_data\n",
    "        self.index_map = index_map\n",
    "        self.matches = []\n",
    "\n",
    "        for match_id in df['match_id'].unique():\n",
    "            for inning in [1, 2]:\n",
    "                match_inning = df[(df['match_id'] == match_id) & (df['inning'] == inning)]\n",
    "                if len(match_inning) > 1:\n",
    "                    self.matches.append(match_inning.reset_index(drop=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(match) - 1 for match in self.matches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cum_idx = 0\n",
    "        for match in self.matches:\n",
    "            match_len = len(match) - 1\n",
    "            if cum_idx + match_len > idx:\n",
    "                over_idx = idx - cum_idx\n",
    "                sequence = match.iloc[:over_idx + 1]\n",
    "                next_row = match.iloc[over_idx + 1]\n",
    "                break\n",
    "            cum_idx += match_len\n",
    "\n",
    "        team1_seq = torch.tensor(sequence['batting_team'].values, dtype=torch.long)\n",
    "        team2_seq = torch.tensor(sequence['bowling_team'].values, dtype=torch.long)\n",
    "\n",
    "        numerical_seq = torch.tensor([\n",
    "            self.numerical_data[self.index_map[sequence.index[i]]]\n",
    "            for i in range(len(sequence))\n",
    "        ], dtype=torch.float32)\n",
    "\n",
    "        runs = torch.tensor(next_row['total_runs'], dtype=torch.float32)\n",
    "        wickets = torch.tensor(next_row['is_wicket'], dtype=torch.float32)\n",
    "\n",
    "        return team1_seq, team2_seq, numerical_seq, runs, wickets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11eebecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    team1_seqs, team2_seqs, num_seqs, runs, wickets = zip(*batch)\n",
    "\n",
    "    team1_seqs = pad_sequence(team1_seqs, batch_first=True, padding_value=0)\n",
    "    team2_seqs = pad_sequence(team2_seqs, batch_first=True, padding_value=0)\n",
    "    num_seqs = pad_sequence(num_seqs, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    runs = torch.stack(runs)\n",
    "    wickets = torch.stack(wickets)\n",
    "\n",
    "    return team1_seqs, team2_seqs, num_seqs, runs, wickets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7620d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IPLDataset(train_df, train_numerical_data, train_index_map)\n",
    "test_dataset = IPLDataset(test_df, test_numerical_data, test_index_map)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8781f9b1",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e54a41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPLModel(nn.Module):\n",
    "    def __init__(self, num_teams, embedding_dim, numerical_dim, hidden_dim):\n",
    "        super(IPLModel, self).__init__()\n",
    "        self.team_embedding = nn.Embedding(num_teams, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=2*embedding_dim + numerical_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc_runs = nn.Linear(hidden_dim, 1)\n",
    "        self.fc_wickets = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, team1_seq, team2_seq, num_seq):\n",
    "        team1_emb = self.team_embedding(team1_seq)  # (batch_size, seq_len, emb_dim)\n",
    "        team2_emb = self.team_embedding(team2_seq)  # (batch_size, seq_len, emb_dim)\n",
    "        x = torch.cat([team1_emb, team2_emb, num_seq], dim=2)  # (batch_size, seq_len, 2*emb_dim + num_dim)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out_runs = self.fc_runs(lstm_out[:, -1, :])  # only use final timestep\n",
    "        out_wickets = self.fc_wickets(lstm_out[:, -1, :])\n",
    "        return out_runs.squeeze(1), out_wickets.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f6411",
   "metadata": {},
   "source": [
    "## Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9062464",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m runs, wickets = runs.to(device), wickets.to(device)\n\u001b[32m     27\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m pred_runs, pred_wickets = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteam1_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteam2_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m loss_runs = criterion(pred_runs, runs)\n\u001b[32m     30\u001b[39m loss_wickets = criterion(pred_wickets, wickets)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Smai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Smai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mIPLModel.forward\u001b[39m\u001b[34m(self, team1_seq, team2_seq, num_seq)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, team1_seq, team2_seq, num_seq):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     team1_emb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mteam_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteam1_seq\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, seq_len, emb_dim)\u001b[39;00m\n\u001b[32m     11\u001b[39m     team2_emb = \u001b[38;5;28mself\u001b[39m.team_embedding(team2_seq)  \u001b[38;5;66;03m# (batch_size, seq_len, emb_dim)\u001b[39;00m\n\u001b[32m     12\u001b[39m     x = torch.cat([team1_emb, team2_emb, num_seq], dim=\u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# (batch_size, seq_len, 2*emb_dim + num_dim)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Smai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Smai/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Smai/.venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Smai/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_teams = len(team_encoder.classes_)\n",
    "model = IPLModel(num_teams=num_teams, embedding_dim=10, numerical_dim=len(numerical_features), hidden_dim=32)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Lists to store metrics for plotting\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_runs_mae = []\n",
    "test_runs_mae = []\n",
    "train_wickets_mae = []\n",
    "test_wickets_mae = []\n",
    "# Add metrics for classification evaluation\n",
    "train_wicket_accuracy = []\n",
    "test_wicket_accuracy = []\n",
    "train_wicket_precision = []\n",
    "test_wicket_precision = []\n",
    "train_wicket_recall = []\n",
    "test_wicket_recall = []\n",
    "train_wicket_f1 = []\n",
    "test_wicket_f1 = []\n",
    "best_test_loss = float(\"inf\")\n",
    "\n",
    "# Function to calculate classification metrics for wicket prediction\n",
    "def calculate_wicket_metrics(pred_wickets, actual_wickets, threshold=0.5):\n",
    "    # Convert predictions to binary using threshold\n",
    "    pred_binary = (pred_wickets > threshold).float()\n",
    "    # Calculate accuracy\n",
    "    accuracy = (pred_binary == actual_wickets).float().mean().item()\n",
    "    \n",
    "    # Calculate TP, FP, FN for precision, recall, F1\n",
    "    true_positives = ((pred_binary == 1) & (actual_wickets == 1)).sum().float().item()\n",
    "    false_positives = ((pred_binary == 1) & (actual_wickets == 0)).sum().float().item()\n",
    "    false_negatives = ((pred_binary == 0) & (actual_wickets == 1)).sum().float().item()\n",
    "    \n",
    "    # Calculate precision, recall, F1\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_r_mae = 0\n",
    "    train_w_mae = 0\n",
    "    all_pred_wickets = []\n",
    "    all_actual_wickets = []\n",
    "    \n",
    "    for team1_seq, team2_seq, num_seq, runs, wickets in train_loader:\n",
    "        team1_seq, team2_seq, num_seq = team1_seq.to(device), team2_seq.to(device), num_seq.to(device)\n",
    "        runs, wickets = runs.to(device), wickets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred_runs, pred_wickets = model(team1_seq, team2_seq, num_seq)\n",
    "        loss_runs = criterion(pred_runs, runs)\n",
    "        loss_wickets = criterion(pred_wickets, wickets)\n",
    "        loss = loss_runs + loss_wickets\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_r_mae += torch.mean(torch.abs(pred_runs - runs)).item()\n",
    "        train_w_mae += torch.mean(torch.abs(pred_wickets - wickets)).item()\n",
    "        \n",
    "        # Store predictions for classification metrics\n",
    "        all_pred_wickets.append(pred_wickets.detach())\n",
    "        all_actual_wickets.append(wickets)\n",
    "\n",
    "    # Calculate classification metrics for the entire epoch\n",
    "    all_pred_wickets = torch.cat(all_pred_wickets)\n",
    "    all_actual_wickets = torch.cat(all_actual_wickets)\n",
    "    w_acc, w_prec, w_rec, w_f1 = calculate_wicket_metrics(all_pred_wickets, all_actual_wickets)\n",
    "    \n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_runs_mae.append(train_r_mae / len(train_loader))\n",
    "    train_wickets_mae.append(train_w_mae / len(train_loader))\n",
    "    train_wicket_accuracy.append(w_acc)\n",
    "    train_wicket_precision.append(w_prec)\n",
    "    train_wicket_recall.append(w_rec)\n",
    "    train_wicket_f1.append(w_f1)\n",
    "\n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_r_mae = 0\n",
    "    test_w_mae = 0\n",
    "    all_pred_wickets = []\n",
    "    all_actual_wickets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for team1_seq, team2_seq, num_seq, runs, wickets in test_loader:\n",
    "            team1_seq, team2_seq, num_seq = team1_seq.to(device), team2_seq.to(device), num_seq.to(device)\n",
    "            runs, wickets = runs.to(device), wickets.to(device)\n",
    "            pred_runs, pred_wickets = model(team1_seq, team2_seq, num_seq)\n",
    "            loss_runs = criterion(pred_runs, runs)\n",
    "            loss_wickets = criterion(pred_wickets, wickets)\n",
    "            loss = loss_runs + loss_wickets\n",
    "            test_loss += loss.item()\n",
    "            test_r_mae += torch.mean(torch.abs(pred_runs - runs)).item()\n",
    "            test_w_mae += torch.mean(torch.abs(pred_wickets - wickets)).item()\n",
    "            \n",
    "            # Store predictions for classification metrics\n",
    "            all_pred_wickets.append(pred_wickets)\n",
    "            all_actual_wickets.append(wickets)\n",
    "    \n",
    "    # Calculate classification metrics for the entire epoch\n",
    "    all_pred_wickets = torch.cat(all_pred_wickets)\n",
    "    all_actual_wickets = torch.cat(all_actual_wickets)\n",
    "    w_acc, w_prec, w_rec, w_f1 = calculate_wicket_metrics(all_pred_wickets, all_actual_wickets)\n",
    "    \n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "    test_runs_mae.append(test_r_mae / len(test_loader))\n",
    "    test_wickets_mae.append(test_w_mae / len(test_loader))\n",
    "    test_wicket_accuracy.append(w_acc)\n",
    "    test_wicket_precision.append(w_prec)\n",
    "    test_wicket_recall.append(w_rec)\n",
    "    test_wicket_f1.append(w_f1)\n",
    "\n",
    "    # Print epoch results with additional metrics\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}\")\n",
    "    print(f\"Train Runs MAE: {train_runs_mae[-1]:.4f}, Test Runs MAE: {test_runs_mae[-1]:.4f}\")\n",
    "    print(f\"Train Wickets MAE: {train_wickets_mae[-1]:.4f}, Test Wickets MAE: {test_wickets_mae[-1]:.4f}\")\n",
    "    print(f\"Wicket Metrics - Train Acc: {train_wicket_accuracy[-1]:.4f}, Test Acc: {test_wicket_accuracy[-1]:.4f}\")\n",
    "    print(f\"Wicket Metrics - Train F1: {train_wicket_f1[-1]:.4f}, Test F1: {test_wicket_f1[-1]:.4f}\")\n",
    "    print(f\"Wicket Metrics - Train Precision: {train_wicket_precision[-1]:.4f}, Test Precision: {test_wicket_precision[-1]:.4f}\")\n",
    "    print(f\"Wicket Metrics - Train Recall: {train_wicket_recall[-1]:.4f}, Test Recall: {test_wicket_recall[-1]:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if test_losses[-1] < best_test_loss:\n",
    "        best_test_loss = test_losses[-1]\n",
    "        torch.save(model.state_dict(), 'best_ipl_model.pth')\n",
    "        print(f\"Best model saved with Test Loss: {best_test_loss:.4f}\")\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"CUDA Memory Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")\n",
    "        \n",
    "epochs = range(1, num_epochs + 1)\n",
    "# Plot 1: Training vs Testing Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(epochs, test_losses, label='Test Loss', marker='o')\n",
    "plt.title('Training and Testing Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('loss_over_epochs.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: Training vs Testing Runs MAE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_runs_mae, label='Train Runs MAE', marker='o')\n",
    "plt.plot(epochs, test_runs_mae, label='Test Runs MAE', marker='o')\n",
    "plt.title('Training and Testing Runs MAE Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE (Runs)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('runs_mae_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 3: Training vs Testing Wickets MAE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_wickets_mae, label='Train Wickets MAE', marker='o')\n",
    "plt.plot(epochs, test_wickets_mae, label='Test Wickets MAE', marker='o')\n",
    "plt.title('Training and Testing Wickets MAE Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE (Wickets)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('wickets_mae_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 4: Wicket Classification Metrics - Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_wicket_accuracy, label='Train Accuracy', marker='o')\n",
    "plt.plot(epochs, test_wicket_accuracy, label='Test Accuracy', marker='o')\n",
    "plt.title('Wicket Prediction Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('wicket_accuracy_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 5: Wicket Classification Metrics - F1 Score\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_wicket_f1, label='Train F1', marker='o')\n",
    "plt.plot(epochs, test_wicket_f1, label='Test F1', marker='o')\n",
    "plt.title('Wicket Prediction F1 Score Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('wicket_f1_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Plots saved as 'loss_over_epochs.png', 'runs_mae_over_epochs.png', 'wickets_mae_over_epochs.png', 'wicket_accuracy_over_epochs.png', and 'wicket_f1_over_epochs.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8fa96",
   "metadata": {},
   "source": [
    "# Load the best model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6459307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¥ Loading best model for evaluation...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IPLModel(\n",
       "  (team_embedding): Embedding(14, 10)\n",
       "  (lstm): LSTM(25, 32, batch_first=True)\n",
       "  (fc_runs): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (fc_wickets): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"\\nðŸ“¥ Loading best model for evaluation...\")\n",
    "model.load_state_dict(torch.load('best_ipl_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4ce0c",
   "metadata": {},
   "source": [
    "## Simulating the cricket phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def simulate_match(model, team_encoder, scaler, device):\n",
    "#     model.eval()\n",
    "#     valid_teams = list(team_encoder.classes_)\n",
    "#     print(\"\\nAvailable teams:\", valid_teams)\n",
    "\n",
    "#     # 1. Get user input\n",
    "#     batting_team = input(\"Batting team: \").strip()\n",
    "#     bowling_team = input(\"Bowling team: \").strip()\n",
    "#     if batting_team not in valid_teams or bowling_team not in valid_teams:\n",
    "#         print(\"âŒ Invalid team names.\")\n",
    "#         return\n",
    "    \n",
    "#     try:\n",
    "#         innings = int(input(\"Which innings? (1 or 2): \"))\n",
    "#         current_over = int(input(\"Current completed over (e.g., 5): \"))\n",
    "#         current_runs = int(input(\"Current total runs: \"))\n",
    "#         current_wickets = int(input(\"Current total wickets: \"))\n",
    "#         if innings == 2:\n",
    "#             target_score = int(input(\"Target score to win: \"))\n",
    "#         overs_to_simulate = int(input(\"How many overs do you want to simulate? (e.g., 5): \"))\n",
    "#     except ValueError:\n",
    "#         print(\"âŒ Invalid input.\")\n",
    "#         return\n",
    "\n",
    "#     # 2. Initialize state\n",
    "#     total_runs = current_runs\n",
    "#     total_wickets = current_wickets\n",
    "\n",
    "#     team1 = torch.tensor([team_encoder.transform([batting_team])[0]], dtype=torch.long).to(device)\n",
    "#     team2 = torch.tensor([team_encoder.transform([bowling_team])[0]], dtype=torch.long).to(device)\n",
    "\n",
    "#     print(f\"\\nðŸŽ¯ Simulating from over {current_over + 1} to {current_over + overs_to_simulate}...\\n\")\n",
    "\n",
    "#     for i in range(1, overs_to_simulate + 1):\n",
    "#         over_num = current_over + i\n",
    "#         if over_num > 20:\n",
    "#             break  # max 20 overs\n",
    "\n",
    "#         run_rate = total_runs / over_num if over_num > 0 else 0\n",
    "#         target_left = (target_score - total_runs) if innings == 2 else 0\n",
    "#         req_runrate = (target_left / (20 - over_num)) if innings == 2 and (20 - over_num) > 0 else 0\n",
    "#         season_weight = 1  # default neutral\n",
    "\n",
    "#         input_data = scaler.transform([[over_num, run_rate, req_runrate, target_left, season_weight]])\n",
    "#         num_data = torch.tensor(input_data, dtype=torch.float32).to(device)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             pred_runs, pred_wickets = model(team1, team2, num_data)\n",
    "\n",
    "#         pred_runs_val = max(0, pred_runs.item())\n",
    "#         pred_wickets_val = max(0, pred_wickets.item())\n",
    "\n",
    "#         total_runs += pred_runs_val\n",
    "#         total_wickets += round(pred_wickets_val)\n",
    "\n",
    "#         print(f\"ðŸŸ¡ Over {over_num}: +{pred_runs_val:.2f} runs, +{pred_wickets_val:.2f} wickets\")\n",
    "\n",
    "#         if total_wickets >= 10:\n",
    "#             print(\"ðŸ”´ All out!\")\n",
    "#             break\n",
    "\n",
    "#     print(f\"\\nðŸ Final Projected Score: {int(total_runs)}/{min(int(total_wickets), 10)}\")\n",
    "\n",
    "#     if innings == 2:\n",
    "#         if total_runs > target_score:\n",
    "#             print(\"âœ… Projected WIN by\", int(total_runs - target_score), \"runs\")\n",
    "#         elif total_runs < target_score:\n",
    "#             print(\"âŒ Projected LOSS by\", int(target_score - total_runs), \"runs\")\n",
    "#         else:\n",
    "#             print(\"ðŸ¤ Projected TIE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c4e2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available teams: ['Chennai Super Kings', 'Delhi Capitals', 'Gujarat Lions', 'Gujarat Titans', 'Kochi Tuskers Kerala', 'Kolkata Knight Riders', 'Lucknow Super Giants', 'Mumbai Indians', 'Pune Warriors', 'Punjab Kings', 'Rajasthan Royals', 'Rising Pune Supergiant', 'Royal Challengers Bengaluru', 'Sunrisers Hyderabad']\n",
      "âŒ Invalid team names.\n"
     ]
    }
   ],
   "source": [
    "# simulate_match(model, team_encoder, scaler, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
