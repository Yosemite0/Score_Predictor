{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "020a349f",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89596e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aa34d87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Memory Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c770db1",
   "metadata": {},
   "source": [
    "## Loading required data and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b185dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data/updated_over_by_over_data_set.csv')\n",
    "\n",
    "df['season'] = df['season'].astype(str)\n",
    "df['season_year'] = df['season'].apply(lambda x: int(x.split('/')[0]))\n",
    "max_year = 2024\n",
    "df['season_weight'] = np.exp(-0.1 * (max_year - df['season_year']))\n",
    "\n",
    "# Encode teams using LabelEncoder + Embedding\n",
    "team_encoder = LabelEncoder()\n",
    "df['batting_team'] = team_encoder.fit_transform(df['batting_team'])\n",
    "df['bowling_team'] = team_encoder.fit_transform(df['bowling_team'])\n",
    "\n",
    "# Numerical features\n",
    "numerical_features = ['over', 'run_rate', 'req_runrate', 'target_left', 'season_weight']\n",
    "scaler = StandardScaler()\n",
    "numerical_data = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Step 3: Split the dataset into train and test (by match_id)\n",
    "match_ids = df['match_id'].unique()\n",
    "train_match_ids, test_match_ids = train_test_split(match_ids, test_size=0.2, random_state=42)\n",
    "train_df = df[df['match_id'].isin(train_match_ids)].reset_index(drop=True)\n",
    "test_df = df[df['match_id'].isin(test_match_ids)].reset_index(drop=True)\n",
    "\n",
    "# Prepare numerical data for train and test sets\n",
    "train_numerical_data = scaler.transform(train_df[numerical_features])\n",
    "test_numerical_data = scaler.transform(test_df[numerical_features])\n",
    "\n",
    "# Create index mappings for train and test DataFrames\n",
    "train_index_map = {old_idx: new_idx for new_idx, old_idx in enumerate(train_df.index)}\n",
    "test_index_map = {old_idx: new_idx for new_idx, old_idx in enumerate(test_df.index)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc9b45",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "723e2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPLDataset(Dataset):\n",
    "    def __init__(self, df, numerical_data, index_map):\n",
    "        self.df = df\n",
    "        self.numerical_data = numerical_data\n",
    "        self.index_map = index_map\n",
    "        self.matches = []\n",
    "\n",
    "        for match_id in df['match_id'].unique():\n",
    "            for inning in [1, 2]:\n",
    "                match_inning = df[(df['match_id'] == match_id) & (df['inning'] == inning)]\n",
    "                if len(match_inning) > 1:\n",
    "                    self.matches.append(match_inning.reset_index(drop=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(match) - 1 for match in self.matches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cum_idx = 0\n",
    "        for match in self.matches:\n",
    "            match_len = len(match) - 1\n",
    "            if cum_idx + match_len > idx:\n",
    "                over_idx = idx - cum_idx\n",
    "                sequence = match.iloc[:over_idx + 1]\n",
    "                next_row = match.iloc[over_idx + 1]\n",
    "                break\n",
    "            cum_idx += match_len\n",
    "\n",
    "        team1_seq = torch.tensor(sequence['batting_team'].values, dtype=torch.long)\n",
    "        team2_seq = torch.tensor(sequence['bowling_team'].values, dtype=torch.long)\n",
    "\n",
    "        numerical_seq = torch.tensor([\n",
    "            self.numerical_data[self.index_map[sequence.index[i]]]\n",
    "            for i in range(len(sequence))\n",
    "        ], dtype=torch.float32)\n",
    "\n",
    "        runs = torch.tensor(next_row['total_runs'], dtype=torch.float32)\n",
    "        wickets = torch.tensor(next_row['is_wicket'], dtype=torch.float32)\n",
    "\n",
    "        return team1_seq, team2_seq, numerical_seq, runs, wickets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "11eebecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    team1_seqs, team2_seqs, num_seqs, runs, wickets = zip(*batch)\n",
    "\n",
    "    team1_seqs = pad_sequence(team1_seqs, batch_first=True, padding_value=0)\n",
    "    team2_seqs = pad_sequence(team2_seqs, batch_first=True, padding_value=0)\n",
    "    num_seqs = pad_sequence(num_seqs, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    runs = torch.stack(runs)\n",
    "    wickets = torch.stack(wickets)\n",
    "\n",
    "    return team1_seqs, team2_seqs, num_seqs, runs, wickets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7620d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IPLDataset(train_df, train_numerical_data, train_index_map)\n",
    "test_dataset = IPLDataset(test_df, test_numerical_data, test_index_map)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8781f9b1",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e54a41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPLModel(nn.Module):\n",
    "    def __init__(self, num_teams, embedding_dim, numerical_dim, hidden_dim):\n",
    "        super(IPLModel, self).__init__()\n",
    "        self.team_embedding = nn.Embedding(num_teams, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=2*embedding_dim + numerical_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc_runs = nn.Linear(hidden_dim, 1)\n",
    "        self.fc_wickets = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, team1_seq, team2_seq, num_seq):\n",
    "        team1_emb = self.team_embedding(team1_seq)  # (batch_size, seq_len, emb_dim)\n",
    "        team2_emb = self.team_embedding(team2_seq)  # (batch_size, seq_len, emb_dim)\n",
    "        x = torch.cat([team1_emb, team2_emb, num_seq], dim=2)  # (batch_size, seq_len, 2*emb_dim + num_dim)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out_runs = self.fc_runs(lstm_out[:, -1, :])  # only use final timestep\n",
    "        out_wickets = self.fc_wickets(lstm_out[:, -1, :])\n",
    "        return out_runs.squeeze(1), out_wickets.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f6411",
   "metadata": {},
   "source": [
    "## Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9062464",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_teams = len(team_encoder.classes_)\n",
    "model = IPLModel(num_teams=num_teams, embedding_dim=10, numerical_dim=len(numerical_features), hidden_dim=32)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Lists to store metrics for plotting\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_runs_mae = []\n",
    "test_runs_mae = []\n",
    "train_wickets_mae = []\n",
    "test_wickets_mae = []\n",
    "# Add metrics for classification evaluation\n",
    "train_wicket_accuracy = []\n",
    "test_wicket_accuracy = []\n",
    "train_wicket_precision = []\n",
    "test_wicket_precision = []\n",
    "train_wicket_recall = []\n",
    "test_wicket_recall = []\n",
    "train_wicket_f1 = []\n",
    "test_wicket_f1 = []\n",
    "train_runs_accuracy = []\n",
    "test_runs_accuracy = []\n",
    "train_runs_precision = []\n",
    "test_runs_precision = []\n",
    "train_runs_recall = []\n",
    "test_runs_recall = []\n",
    "train_runs_f1 = []\n",
    "test_runs_f1 = []\n",
    "best_test_loss = float(\"inf\")\n",
    "\n",
    "\n",
    "def calculate_runs_metrics(pred_runs, actual_runs, threshold=1.0):\n",
    "    # Consider a prediction \"correct\" if it's within threshold runs of actual\n",
    "    correct_prediction = (torch.abs(pred_runs - actual_runs) <= threshold).float()\n",
    "    accuracy = correct_prediction.mean().item()\n",
    "    \n",
    "    # Define \"positive\" as cases where actual runs are above the median\n",
    "    median_runs = torch.median(actual_runs)\n",
    "    actual_positive = (actual_runs > median_runs).float()\n",
    "    pred_positive = (pred_runs > median_runs).float()\n",
    "    \n",
    "    true_positives = ((pred_positive == 1) & (actual_positive == 1)).sum().float().item()\n",
    "    false_positives = ((pred_positive == 1) & (actual_positive == 0)).sum().float().item()\n",
    "    false_negatives = ((pred_positive == 0) & (actual_positive == 1)).sum().float().item()\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Function to calculate classification metrics for wicket prediction\n",
    "def calculate_wicket_metrics(pred_wickets, actual_wickets, threshold=0.5):\n",
    "    # Convert predictions to binary using threshold\n",
    "    pred_binary = (pred_wickets > threshold).float()\n",
    "    # Calculate accuracy\n",
    "    accuracy = (pred_binary == actual_wickets).float().mean().item()\n",
    "    \n",
    "    # Calculate TP, FP, FN for precision, recall, F1\n",
    "    true_positives = ((pred_binary == 1) & (actual_wickets == 1)).sum().float().item()\n",
    "    false_positives = ((pred_binary == 1) & (actual_wickets == 0)).sum().float().item()\n",
    "    false_negatives = ((pred_binary == 0) & (actual_wickets == 1)).sum().float().item()\n",
    "    \n",
    "    # Calculate precision, recall, F1\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_r_mae = 0\n",
    "    train_w_mae = 0\n",
    "    all_pred_wickets = []\n",
    "    all_actual_wickets = []\n",
    "    all_pred_runs = []\n",
    "    all_actual_runs = []\n",
    "    \n",
    "    for team1_seq, team2_seq, num_seq, runs, wickets in train_loader:\n",
    "        team1_seq, team2_seq, num_seq = team1_seq.to(device), team2_seq.to(device), num_seq.to(device)\n",
    "        runs, wickets = runs.to(device), wickets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred_runs, pred_wickets = model(team1_seq, team2_seq, num_seq)\n",
    "        loss_runs = criterion(pred_runs, runs)\n",
    "        loss_wickets = criterion(pred_wickets, wickets)\n",
    "        loss = loss_runs + loss_wickets\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_r_mae += torch.mean(torch.abs(pred_runs - runs)).item()\n",
    "        train_w_mae += torch.mean(torch.abs(pred_wickets - wickets)).item()\n",
    "        \n",
    "        # Store predictions for classification metrics\n",
    "        all_pred_wickets.append(pred_wickets.detach())\n",
    "        all_actual_wickets.append(wickets)\n",
    "        all_pred_runs.append(pred_runs.detach())\n",
    "        all_actual_runs.append(runs)\n",
    "\n",
    "    # Calculate classification metrics for the entire epoch\n",
    "    all_pred_wickets = torch.cat(all_pred_wickets)\n",
    "    all_actual_wickets = torch.cat(all_actual_wickets)\n",
    "    w_acc, w_prec, w_rec, w_f1 = calculate_wicket_metrics(all_pred_wickets, all_actual_wickets)\n",
    "\n",
    "\n",
    "    all_pred_runs = torch.cat(all_pred_runs)\n",
    "    all_actual_runs = torch.cat(all_actual_runs)\n",
    "    r_acc, r_prec, r_rec, r_f1 = calculate_runs_metrics(all_pred_runs, all_actual_runs)\n",
    "    \n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_runs_mae.append(train_r_mae / len(train_loader))\n",
    "    train_wickets_mae.append(train_w_mae / len(train_loader))\n",
    "\n",
    "    train_wicket_accuracy.append(w_acc)\n",
    "    train_wicket_precision.append(w_prec)\n",
    "    train_wicket_recall.append(w_rec)\n",
    "    train_wicket_f1.append(w_f1)\n",
    "\n",
    "    train_runs_accuracy.append(r_acc)\n",
    "    train_runs_precision.append(r_prec)\n",
    "    train_runs_recall.append(r_rec)\n",
    "    train_runs_f1.append(r_f1)\n",
    "\n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_r_mae = 0\n",
    "    test_w_mae = 0\n",
    "    all_pred_wickets = []\n",
    "    all_actual_wickets = []\n",
    "    all_pred_runs = []\n",
    "    all_actual_runs = []\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for team1_seq, team2_seq, num_seq, runs, wickets in test_loader:\n",
    "            team1_seq, team2_seq, num_seq = team1_seq.to(device), team2_seq.to(device), num_seq.to(device)\n",
    "            runs, wickets = runs.to(device), wickets.to(device)\n",
    "            pred_runs, pred_wickets = model(team1_seq, team2_seq, num_seq)\n",
    "            loss_runs = criterion(pred_runs, runs)\n",
    "            loss_wickets = criterion(pred_wickets, wickets)\n",
    "            loss = loss_runs + loss_wickets\n",
    "            test_loss += loss.item()\n",
    "            test_r_mae += torch.mean(torch.abs(pred_runs - runs)).item()\n",
    "            test_w_mae += torch.mean(torch.abs(pred_wickets - wickets)).item()\n",
    "            \n",
    "            # Store predictions for classification metrics\n",
    "            all_pred_wickets.append(pred_wickets)\n",
    "            all_actual_wickets.append(wickets)\n",
    "            all_pred_runs.append(pred_runs)\n",
    "            all_actual_runs.append(runs)\n",
    "    \n",
    "    # Calculate classification metrics for the entire epoch\n",
    "    all_pred_wickets = torch.cat(all_pred_wickets)\n",
    "    all_actual_wickets = torch.cat(all_actual_wickets)\n",
    "    w_acc, w_prec, w_rec, w_f1 = calculate_wicket_metrics(all_pred_wickets, all_actual_wickets)\n",
    "\n",
    "    all_pred_runs = torch.cat(all_pred_runs)\n",
    "    all_actual_runs = torch.cat(all_actual_runs)\n",
    "    r_acc, r_prec, r_rec, r_f1 = calculate_runs_metrics(all_pred_runs, all_actual_runs)\n",
    "    \n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "    test_runs_mae.append(test_r_mae / len(test_loader))\n",
    "    test_wickets_mae.append(test_w_mae / len(test_loader))\n",
    "    test_wicket_accuracy.append(w_acc)\n",
    "    test_wicket_precision.append(w_prec)\n",
    "    test_wicket_recall.append(w_rec)\n",
    "    test_wicket_f1.append(w_f1)\n",
    "\n",
    "\n",
    "    test_runs_accuracy.append(r_acc)\n",
    "    test_runs_precision.append(r_prec)\n",
    "    test_runs_recall.append(r_rec)\n",
    "    test_runs_f1.append(r_f1)\n",
    "\n",
    "    # Print epoch results with additional metrics\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}\")\n",
    "    print(f\"Train Runs MAE: {train_runs_mae[-1]:.4f}, Test Runs MAE: {test_runs_mae[-1]:.4f}\")\n",
    "    print(f\"Train Wickets MAE: {train_wickets_mae[-1]:.4f}, Test Wickets MAE: {test_wickets_mae[-1]:.4f}\")\n",
    "    print(f\"Runs Metrics - Train Acc: {train_runs_accuracy[-1]:.4f}, Test Acc: {test_runs_accuracy[-1]:.4f}\")\n",
    "    print(f\"Runs Metrics - Train F1: {train_runs_f1[-1]:.4f}, Test F1: {test_runs_f1[-1]:.4f}\")\n",
    "    print(f\"Runs Metrics - Train Precision: {train_runs_precision[-1]:.4f}, Test Precision: {test_runs_precision[-1]:.4f}\")\n",
    "    print(f\"Runs Metrics - Train Recall: {train_runs_recall[-1]:.4f}, Test Recall: {test_runs_recall[-1]:.4f}\")\n",
    "    print(f\"Wicket Metrics - Train Acc: {train_wicket_accuracy[-1]:.4f}, Test Acc: {test_wicket_accuracy[-1]:.4f}\")\n",
    "    print(f\"Wicket Metrics - Train F1: {train_wicket_f1[-1]:.4f}, Test F1: {test_wicket_f1[-1]:.4f}\")\n",
    "    print(f\"Wicket Metrics - Train Precision: {train_wicket_precision[-1]:.4f}, Test Precision: {test_wicket_precision[-1]:.4f}\")\n",
    "    print(f\"Wicket Metrics - Train Recall: {train_wicket_recall[-1]:.4f}, Test Recall: {test_wicket_recall[-1]:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if test_losses[-1] < best_test_loss:\n",
    "        best_test_loss = test_losses[-1]\n",
    "        torch.save(model.state_dict(), 'best_ipl_model.pth')\n",
    "        print(f\"Best model saved with Test Loss: {best_test_loss:.4f}\")\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"CUDA Memory Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")\n",
    "        \n",
    "epochs = range(1, num_epochs + 1)\n",
    "# Plot 1: Training vs Testing Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(epochs, test_losses, label='Test Loss', marker='o')\n",
    "plt.title('Training and Testing Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('loss_over_epochs.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: Training vs Testing Runs MAE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_runs_mae, label='Train Runs MAE', marker='o')\n",
    "plt.plot(epochs, test_runs_mae, label='Test Runs MAE', marker='o')\n",
    "plt.title('Training and Testing Runs MAE Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE (Runs)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('runs_mae_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 3: Training vs Testing Wickets MAE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_wickets_mae, label='Train Wickets MAE', marker='o')\n",
    "plt.plot(epochs, test_wickets_mae, label='Test Wickets MAE', marker='o')\n",
    "plt.title('Training and Testing Wickets MAE Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE (Wickets)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('wickets_mae_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 4: Wicket Classification Metrics - Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_wicket_accuracy, label='Train Accuracy', marker='o')\n",
    "plt.plot(epochs, test_wicket_accuracy, label='Test Accuracy', marker='o')\n",
    "plt.title('Wicket Prediction Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('wicket_accuracy_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 5: Wicket Classification Metrics - F1 Score\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_wicket_f1, label='Train F1', marker='o')\n",
    "plt.plot(epochs, test_wicket_f1, label='Test F1', marker='o')\n",
    "plt.title('Wicket Prediction F1 Score Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('wicket_f1_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_runs_accuracy, label='Train Accuracy', marker='o')\n",
    "plt.plot(epochs, test_runs_accuracy, label='Test Accuracy', marker='o')\n",
    "plt.title('Runs Prediction Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('runs_accuracy_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 7: Runs Classification Metrics - F1 Score\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_runs_f1, label='Train F1', marker='o')\n",
    "plt.plot(epochs, test_runs_f1, label='Test F1', marker='o')\n",
    "plt.title('Runs Prediction F1 Score Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('runs_f1_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 8: Runs Classification Metrics - Precision \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_runs_precision, label='Train Precision', marker='o')\n",
    "plt.plot(epochs, test_runs_precision, label='Test Precision', marker='o')\n",
    "plt.title('Runs Prediction Precision Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('runs_precision_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 9: Runs Classification Metrics - Recall\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_runs_recall, label='Train Recall', marker='o')\n",
    "plt.plot(epochs, test_runs_recall, label='Test Recall', marker='o')\n",
    "plt.title('Runs Prediction Recall Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('runs_recall_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Plots saved as 'loss_over_epochs.png', 'runs_mae_over_epochs.png', 'wickets_mae_over_epochs.png', 'wicket_accuracy_over_epochs.png', and 'wicket_f1_over_epochs.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8fa96",
   "metadata": {},
   "source": [
    "# Load the best model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6459307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¥ Loading best model for evaluation...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IPLModel(\n",
       "  (team_embedding): Embedding(14, 10)\n",
       "  (lstm): LSTM(25, 32, batch_first=True)\n",
       "  (fc_runs): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (fc_wickets): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"\\nðŸ“¥ Loading best model for evaluation...\")\n",
    "model.load_state_dict(torch.load('best_ipl_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4ce0c",
   "metadata": {},
   "source": [
    "## Simulating the cricket phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def simulate_match(model, team_encoder, scaler, device):\n",
    "#     model.eval()\n",
    "#     valid_teams = list(team_encoder.classes_)\n",
    "#     print(\"\\nAvailable teams:\", valid_teams)\n",
    "\n",
    "#     # 1. Get user input\n",
    "#     batting_team = input(\"Batting team: \").strip()\n",
    "#     bowling_team = input(\"Bowling team: \").strip()\n",
    "#     if batting_team not in valid_teams or bowling_team not in valid_teams:\n",
    "#         print(\"âŒ Invalid team names.\")\n",
    "#         return\n",
    "    \n",
    "#     try:\n",
    "#         innings = int(input(\"Which innings? (1 or 2): \"))\n",
    "#         current_over = int(input(\"Current completed over (e.g., 5): \"))\n",
    "#         current_runs = int(input(\"Current total runs: \"))\n",
    "#         current_wickets = int(input(\"Current total wickets: \"))\n",
    "#         if innings == 2:\n",
    "#             target_score = int(input(\"Target score to win: \"))\n",
    "#         overs_to_simulate = int(input(\"How many overs do you want to simulate? (e.g., 5): \"))\n",
    "#     except ValueError:\n",
    "#         print(\"âŒ Invalid input.\")\n",
    "#         return\n",
    "\n",
    "#     # 2. Initialize state\n",
    "#     total_runs = current_runs\n",
    "#     total_wickets = current_wickets\n",
    "\n",
    "#     team1 = torch.tensor([team_encoder.transform([batting_team])[0]], dtype=torch.long).to(device)\n",
    "#     team2 = torch.tensor([team_encoder.transform([bowling_team])[0]], dtype=torch.long).to(device)\n",
    "\n",
    "#     print(f\"\\nðŸŽ¯ Simulating from over {current_over + 1} to {current_over + overs_to_simulate}...\\n\")\n",
    "\n",
    "#     for i in range(1, overs_to_simulate + 1):\n",
    "#         over_num = current_over + i\n",
    "#         if over_num > 20:\n",
    "#             break  # max 20 overs\n",
    "\n",
    "#         run_rate = total_runs / over_num if over_num > 0 else 0\n",
    "#         target_left = (target_score - total_runs) if innings == 2 else 0\n",
    "#         req_runrate = (target_left / (20 - over_num)) if innings == 2 and (20 - over_num) > 0 else 0\n",
    "#         season_weight = 1  # default neutral\n",
    "\n",
    "#         input_data = scaler.transform([[over_num, run_rate, req_runrate, target_left, season_weight]])\n",
    "#         num_data = torch.tensor(input_data, dtype=torch.float32).to(device)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             pred_runs, pred_wickets = model(team1, team2, num_data)\n",
    "\n",
    "#         pred_runs_val = max(0, pred_runs.item())\n",
    "#         pred_wickets_val = max(0, pred_wickets.item())\n",
    "\n",
    "#         total_runs += pred_runs_val\n",
    "#         total_wickets += round(pred_wickets_val)\n",
    "\n",
    "#         print(f\"ðŸŸ¡ Over {over_num}: +{pred_runs_val:.2f} runs, +{pred_wickets_val:.2f} wickets\")\n",
    "\n",
    "#         if total_wickets >= 10:\n",
    "#             print(\"ðŸ”´ All out!\")\n",
    "#             break\n",
    "\n",
    "#     print(f\"\\nðŸ Final Projected Score: {int(total_runs)}/{min(int(total_wickets), 10)}\")\n",
    "\n",
    "#     if innings == 2:\n",
    "#         if total_runs > target_score:\n",
    "#             print(\"âœ… Projected WIN by\", int(total_runs - target_score), \"runs\")\n",
    "#         elif total_runs < target_score:\n",
    "#             print(\"âŒ Projected LOSS by\", int(target_score - total_runs), \"runs\")\n",
    "#         else:\n",
    "#             print(\"ðŸ¤ Projected TIE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c4e2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available teams: ['Chennai Super Kings', 'Delhi Capitals', 'Gujarat Lions', 'Gujarat Titans', 'Kochi Tuskers Kerala', 'Kolkata Knight Riders', 'Lucknow Super Giants', 'Mumbai Indians', 'Pune Warriors', 'Punjab Kings', 'Rajasthan Royals', 'Rising Pune Supergiant', 'Royal Challengers Bengaluru', 'Sunrisers Hyderabad']\n",
      "âŒ Invalid team names.\n"
     ]
    }
   ],
   "source": [
    "# simulate_match(model, team_encoder, scaler, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
