{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "020a349f",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "89596e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa34d87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Memory Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c770db1",
   "metadata": {},
   "source": [
    "## Loading required data and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b185dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data/updated_over_by_over_data_set.csv')\n",
    "\n",
    "df['season'] = df['season'].astype(str)\n",
    "df['season_year'] = df['season'].apply(lambda x: int(x.split('/')[0]))\n",
    "max_year = 2024\n",
    "df['season_weight'] = np.exp(-0.1 * (max_year - df['season_year']))\n",
    "\n",
    "# Encode teams using LabelEncoder + Embedding\n",
    "team_encoder = LabelEncoder()\n",
    "df['batting_team'] = team_encoder.fit_transform(df['batting_team'])\n",
    "df['bowling_team'] = team_encoder.fit_transform(df['bowling_team'])\n",
    "\n",
    "\n",
    "numerical_features = ['over', 'run_rate', 'req_runrate', 'target_left', 'season_weight']\n",
    "scaler = StandardScaler()\n",
    "numerical_data = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "\n",
    "match_ids = df['match_id'].unique()\n",
    "train_match_ids, test_match_ids = train_test_split(match_ids, test_size=0.2, random_state=42)\n",
    "train_df = df[df['match_id'].isin(train_match_ids)].reset_index(drop=True)\n",
    "test_df = df[df['match_id'].isin(test_match_ids)].reset_index(drop=True)\n",
    "\n",
    "# Prepare numerical data for train and test sets\n",
    "train_numerical_data = scaler.transform(train_df[numerical_features])\n",
    "test_numerical_data = scaler.transform(test_df[numerical_features])\n",
    "\n",
    "# Create index mappings for train and test DataFrames\n",
    "train_index_map = {old_idx: new_idx for new_idx, old_idx in enumerate(train_df.index)}\n",
    "test_index_map = {old_idx: new_idx for new_idx, old_idx in enumerate(test_df.index)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc9b45",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "723e2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPLDataset(Dataset):\n",
    "    def __init__(self, df, numerical_data, index_map):\n",
    "        self.df = df\n",
    "        self.numerical_data = numerical_data\n",
    "        self.index_map = index_map\n",
    "        self.matches = []\n",
    "\n",
    "        for match_id in df['match_id'].unique():\n",
    "            for inning in [1, 2]:\n",
    "                match_inning = df[(df['match_id'] == match_id) & (df['inning'] == inning)]\n",
    "                if len(match_inning) > 1:\n",
    "                    self.matches.append(match_inning.reset_index(drop=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(match) - 1 for match in self.matches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cum_idx = 0\n",
    "        for match in self.matches:\n",
    "            match_len = len(match) - 1\n",
    "            if cum_idx + match_len > idx:\n",
    "                over_idx = idx - cum_idx\n",
    "                sequence = match.iloc[:over_idx + 1]\n",
    "                next_row = match.iloc[over_idx + 1]\n",
    "                break\n",
    "            cum_idx += match_len\n",
    "\n",
    "        team1_seq = torch.tensor(sequence['batting_team'].values, dtype=torch.long)\n",
    "        team2_seq = torch.tensor(sequence['bowling_team'].values, dtype=torch.long)\n",
    "\n",
    "        numerical_seq = torch.tensor([\n",
    "            self.numerical_data[self.index_map[sequence.index[i]]]\n",
    "            for i in range(len(sequence))\n",
    "        ], dtype=torch.float32)\n",
    "\n",
    "        runs = torch.tensor(next_row['total_runs'], dtype=torch.float32)\n",
    "        wickets = torch.tensor(next_row['is_wicket'], dtype=torch.float32)\n",
    "\n",
    "        return team1_seq, team2_seq, numerical_seq, runs, wickets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "11eebecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    team1_seqs, team2_seqs, num_seqs, runs, wickets = zip(*batch)\n",
    "\n",
    "    team1_seqs = pad_sequence(team1_seqs, batch_first=True, padding_value=0)\n",
    "    team2_seqs = pad_sequence(team2_seqs, batch_first=True, padding_value=0)\n",
    "    num_seqs = pad_sequence(num_seqs, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    runs = torch.stack(runs)\n",
    "    wickets = torch.stack(wickets)\n",
    "\n",
    "    return team1_seqs, team2_seqs, num_seqs, runs, wickets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7620d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IPLDataset(train_df, train_numerical_data, train_index_map)\n",
    "test_dataset = IPLDataset(test_df, test_numerical_data, test_index_map)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8781f9b1",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e54a41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPLModelWithTeacherForcing(nn.Module):\n",
    "    def __init__(self, num_teams, embedding_dim, numerical_dim, hidden_dim):\n",
    "        super(IPLModelWithTeacherForcing, self).__init__()\n",
    "        self.team_embedding = nn.Embedding(num_teams, embedding_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=2*embedding_dim + numerical_dim + 2,  # +2 for previous runs/wickets\n",
    "            hidden_size=hidden_dim, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc_runs = nn.Linear(hidden_dim, 1)\n",
    "        self.fc_wickets = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, team1_seq, team2_seq, num_seq, prev_runs=None, prev_wickets=None, teacher_forcing_ratio=0.5):\n",
    "        batch_size, seq_len = team1_seq.shape\n",
    "        team1_emb = self.team_embedding(team1_seq)\n",
    "        team2_emb = self.team_embedding(team2_seq)\n",
    "        \n",
    "        # Initialize outputs\n",
    "        outputs_runs = torch.zeros(batch_size, seq_len, 1).to(team1_seq.device)\n",
    "        outputs_wickets = torch.zeros(batch_size, seq_len, 1).to(team1_seq.device)\n",
    "        \n",
    "        # Initialize previous predictions for first timestep\n",
    "        if prev_runs is None:\n",
    "            prev_runs = torch.zeros(batch_size, 1).to(team1_seq.device)\n",
    "        if prev_wickets is None:\n",
    "            prev_wickets = torch.zeros(batch_size, 1).to(team1_seq.device)\n",
    "        \n",
    "        # Initial hidden state\n",
    "        h_t = None\n",
    "        \n",
    "        # Process sequence step by step\n",
    "        for t in range(seq_len):\n",
    "            # Combine team embeddings, numerical features, and previous predictions\n",
    "            prev_values = torch.cat([prev_runs.unsqueeze(1), prev_wickets.unsqueeze(1)], dim=2)\n",
    "            x_t = torch.cat([\n",
    "                team1_emb[:, t:t+1, :], \n",
    "                team2_emb[:, t:t+1, :], \n",
    "                num_seq[:, t:t+1, :], \n",
    "                prev_values\n",
    "            ], dim=2)\n",
    "            \n",
    "            # LSTM step\n",
    "            lstm_out, h_t = self.lstm(x_t, h_t)\n",
    "            \n",
    "            # Predictions\n",
    "            run_pred = self.fc_runs(lstm_out).squeeze(1)\n",
    "            wicket_pred = self.fc_wickets(lstm_out).squeeze(1)\n",
    "            \n",
    "            # Store predictions\n",
    "            outputs_runs[:, t] = run_pred\n",
    "            outputs_wickets[:, t] = wicket_pred\n",
    "            \n",
    "            # Teacher forcing: decide whether to use ground truth or prediction\n",
    "            use_teacher_forcing = (torch.rand(1).item() < teacher_forcing_ratio)\n",
    "            \n",
    "            if t < seq_len - 1:  # Not needed for the last timestep\n",
    "                if use_teacher_forcing and prev_runs is not None:\n",
    "                    # Use ground truth from training data\n",
    "                    prev_runs = prev_runs  # Use provided ground truth\n",
    "                    prev_wickets = prev_wickets\n",
    "                else:\n",
    "                    # Use model's own predictions\n",
    "                    prev_runs = run_pred\n",
    "                    prev_wickets = wicket_pred\n",
    "        \n",
    "        # Return only final timestep predictions for compatibility with current code\n",
    "        return outputs_runs[:, -1].squeeze(-1), outputs_wickets[:, -1].squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f6411",
   "metadata": {},
   "source": [
    "## Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9062464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (TF ratio: 1.000):\n",
      "Train Loss: 25.5215, Test Loss: 23.4385\n",
      "Train Runs MAE: 3.8868, Test Runs MAE: 3.9463\n",
      "Train Wickets MAE: 0.4498, Test Wickets MAE: 0.4776\n",
      "Runs Metrics - Train Acc: 0.1627, Test Acc: 0.1470\n",
      "Runs Metrics - Train F1: 0.5316, Test F1: 0.5896\n",
      "Wicket Metrics - Train Acc: 0.7256, Test Acc: 0.7163\n",
      "Wicket Metrics - Train F1: 0.0003, Test F1: 0.0898\n",
      "Best model saved with Test Loss: 23.4385\n",
      "Epoch 2/10 (TF ratio: 1.000):\n",
      "Train Loss: 21.8869, Test Loss: 23.0197\n",
      "Train Runs MAE: 3.6762, Test Runs MAE: 3.9037\n",
      "Train Wickets MAE: 0.4549, Test Wickets MAE: 0.4832\n",
      "Runs Metrics - Train Acc: 0.1640, Test Acc: 0.1472\n",
      "Runs Metrics - Train F1: 0.5674, Test F1: 0.5920\n",
      "Wicket Metrics - Train Acc: 0.7256, Test Acc: 0.7157\n",
      "Wicket Metrics - Train F1: 0.0000, Test F1: 0.0788\n",
      "Best model saved with Test Loss: 23.0197\n",
      "Epoch 3/10 (TF ratio: 1.000):\n",
      "Train Loss: 21.6142, Test Loss: 22.3232\n",
      "Train Runs MAE: 3.6548, Test Runs MAE: 3.8215\n",
      "Train Wickets MAE: 0.4471, Test Wickets MAE: 0.4414\n",
      "Runs Metrics - Train Acc: 0.1641, Test Acc: 0.1466\n",
      "Runs Metrics - Train F1: 0.5755, Test F1: 0.5937\n",
      "Wicket Metrics - Train Acc: 0.7219, Test Acc: 0.7133\n",
      "Wicket Metrics - Train F1: 0.0284, Test F1: 0.1369\n",
      "Best model saved with Test Loss: 22.3232\n",
      "Epoch 4/10 (TF ratio: 1.000):\n",
      "Train Loss: 21.3297, Test Loss: 22.1035\n",
      "Train Runs MAE: 3.6312, Test Runs MAE: 3.7981\n",
      "Train Wickets MAE: 0.4351, Test Wickets MAE: 0.4191\n",
      "Runs Metrics - Train Acc: 0.1642, Test Acc: 0.1455\n",
      "Runs Metrics - Train F1: 0.5601, Test F1: 0.5942\n",
      "Wicket Metrics - Train Acc: 0.7005, Test Acc: 0.7154\n",
      "Wicket Metrics - Train F1: 0.2199, Test F1: 0.1274\n",
      "Best model saved with Test Loss: 22.1035\n",
      "Epoch 5/10 (TF ratio: 1.000):\n",
      "Train Loss: 21.2788, Test Loss: 22.1140\n",
      "Train Runs MAE: 3.6277, Test Runs MAE: 3.8092\n",
      "Train Wickets MAE: 0.4336, Test Wickets MAE: 0.4228\n",
      "Runs Metrics - Train Acc: 0.1654, Test Acc: 0.1451\n",
      "Runs Metrics - Train F1: 0.5486, Test F1: 0.5945\n",
      "Wicket Metrics - Train Acc: 0.7048, Test Acc: 0.7155\n",
      "Wicket Metrics - Train F1: 0.2197, Test F1: 0.1335\n"
     ]
    }
   ],
   "source": [
    "# Create model with teacher forcing\n",
    "num_teams = len(team_encoder.classes_)\n",
    "model = IPLModelWithTeacherForcing(\n",
    "    num_teams=num_teams, \n",
    "    embedding_dim=10, \n",
    "    numerical_dim=len(numerical_features), \n",
    "    hidden_dim=32\n",
    ")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def calculate_runs_metrics(pred_runs, actual_runs, threshold=1.0):\n",
    "    # Consider a prediction \"correct\" if it's within threshold runs of actual\n",
    "    correct_prediction = (torch.abs(pred_runs - actual_runs) <= threshold).float()\n",
    "    accuracy = correct_prediction.mean().item()\n",
    "    \n",
    "    # Define \"positive\" as cases where actual runs are above the median\n",
    "    median_runs = torch.median(actual_runs)\n",
    "    actual_positive = (actual_runs > median_runs).float()\n",
    "    pred_positive = (pred_runs > median_runs).float()\n",
    "    \n",
    "    true_positives = ((pred_positive == 1) & (actual_positive == 1)).sum().float().item()\n",
    "    false_positives = ((pred_positive == 1) & (actual_positive == 0)).sum().float().item()\n",
    "    false_negatives = ((pred_positive == 0) & (actual_positive == 1)).sum().float().item()\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Function to calculate classification metrics for wicket prediction\n",
    "def calculate_wicket_metrics(pred_wickets, actual_wickets, threshold=0.5):\n",
    "    # Convert predictions to binary using threshold\n",
    "    pred_binary = (pred_wickets > threshold).float()\n",
    "    # Calculate accuracy\n",
    "    accuracy = (pred_binary == actual_wickets).float().mean().item()\n",
    "    \n",
    "    # Calculate TP, FP, FN for precision, recall, F1\n",
    "    true_positives = ((pred_binary == 1) & (actual_wickets == 1)).sum().float().item()\n",
    "    false_positives = ((pred_binary == 1) & (actual_wickets == 0)).sum().float().item()\n",
    "    false_negatives = ((pred_binary == 0) & (actual_wickets == 1)).sum().float().item()\n",
    "    \n",
    "    # Calculate precision, recall, F1\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "num_epochs = 10\n",
    "# Lists to store metrics for plotting\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_runs_mae = []\n",
    "test_runs_mae = []\n",
    "train_wickets_mae = []\n",
    "test_wickets_mae = []\n",
    "# Classification metrics\n",
    "train_wicket_accuracy = []\n",
    "test_wicket_accuracy = []\n",
    "train_wicket_precision = []\n",
    "test_wicket_precision = []\n",
    "train_wicket_recall = []\n",
    "test_wicket_recall = []\n",
    "train_wicket_f1 = []\n",
    "test_wicket_f1 = []\n",
    "train_runs_accuracy = []\n",
    "test_runs_accuracy = []\n",
    "train_runs_precision = []\n",
    "test_runs_precision = []\n",
    "train_runs_recall = []\n",
    "test_runs_recall = []\n",
    "train_runs_f1 = []\n",
    "test_runs_f1 = []\n",
    "best_test_loss = float(\"inf\")\n",
    "\n",
    "# Teacher forcing parameters\n",
    "initial_tf_ratio = 1  # Start with high teacher forcing\n",
    "final_tf_ratio = 1    # End with low teacher forcing\n",
    "tf_decay = (final_tf_ratio / initial_tf_ratio) ** (1 / num_epochs)\n",
    "tf_ratio = initial_tf_ratio\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_r_mae = 0\n",
    "    train_w_mae = 0\n",
    "    all_pred_wickets = []\n",
    "    all_actual_wickets = []\n",
    "    all_pred_runs = []\n",
    "    all_actual_runs = []\n",
    "    \n",
    "    for team1_seq, team2_seq, num_seq, runs, wickets in train_loader:\n",
    "        team1_seq, team2_seq, num_seq = team1_seq.to(device), team2_seq.to(device), num_seq.to(device)\n",
    "        runs, wickets = runs.to(device), wickets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Since we don't have direct access to previous runs/wickets in our dataset,\n",
    "        # we'll create placeholder values\n",
    "        batch_size = team1_seq.size(0)\n",
    "        prev_runs = torch.zeros(batch_size, 1).to(device)\n",
    "        prev_wickets = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        # Forward pass with teacher forcing\n",
    "        pred_runs, pred_wickets = model(\n",
    "            team1_seq, team2_seq, num_seq,\n",
    "            prev_runs=prev_runs,\n",
    "            prev_wickets=prev_wickets,\n",
    "            teacher_forcing_ratio=tf_ratio\n",
    "        )\n",
    "        \n",
    "        loss_runs = criterion(pred_runs, runs)\n",
    "        loss_wickets = criterion(pred_wickets, wickets)\n",
    "        loss = loss_runs + loss_wickets\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_r_mae += torch.mean(torch.abs(pred_runs - runs)).item()\n",
    "        train_w_mae += torch.mean(torch.abs(pred_wickets - wickets)).item()\n",
    "        \n",
    "        # Store predictions for classification metrics\n",
    "        all_pred_wickets.append(pred_wickets.detach())\n",
    "        all_actual_wickets.append(wickets)\n",
    "        all_pred_runs.append(pred_runs.detach())\n",
    "        all_actual_runs.append(runs)\n",
    "\n",
    "    # Decay teacher forcing ratio for next epoch\n",
    "    tf_ratio *= tf_decay\n",
    "    \n",
    "    # Calculate classification metrics for the entire epoch\n",
    "    all_pred_wickets = torch.cat(all_pred_wickets)\n",
    "    all_actual_wickets = torch.cat(all_actual_wickets)\n",
    "    w_acc, w_prec, w_rec, w_f1 = calculate_wicket_metrics(all_pred_wickets, all_actual_wickets)\n",
    "\n",
    "    all_pred_runs = torch.cat(all_pred_runs)\n",
    "    all_actual_runs = torch.cat(all_actual_runs)\n",
    "    r_acc, r_prec, r_rec, r_f1 = calculate_runs_metrics(all_pred_runs, all_actual_runs)\n",
    "    \n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_runs_mae.append(train_r_mae / len(train_loader))\n",
    "    train_wickets_mae.append(train_w_mae / len(train_loader))\n",
    "\n",
    "    train_wicket_accuracy.append(w_acc)\n",
    "    train_wicket_precision.append(w_prec)\n",
    "    train_wicket_recall.append(w_rec)\n",
    "    train_wicket_f1.append(w_f1)\n",
    "\n",
    "    train_runs_accuracy.append(r_acc)\n",
    "    train_runs_precision.append(r_prec)\n",
    "    train_runs_recall.append(r_rec)\n",
    "    train_runs_f1.append(r_f1)\n",
    "\n",
    "    # Testing phase - no teacher forcing during evaluation\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_r_mae = 0\n",
    "    test_w_mae = 0\n",
    "    all_pred_wickets = []\n",
    "    all_actual_wickets = []\n",
    "    all_pred_runs = []\n",
    "    all_actual_runs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for team1_seq, team2_seq, num_seq, runs, wickets in test_loader:\n",
    "            team1_seq, team2_seq, num_seq = team1_seq.to(device), team2_seq.to(device), num_seq.to(device)\n",
    "            runs, wickets = runs.to(device), wickets.to(device)\n",
    "            \n",
    "            batch_size = team1_seq.size(0)\n",
    "            prev_runs = torch.zeros(batch_size, 1).to(device)\n",
    "            prev_wickets = torch.zeros(batch_size, 1).to(device)\n",
    "            \n",
    "            # No teacher forcing during evaluation (tf_ratio=0)\n",
    "            pred_runs, pred_wickets = model(\n",
    "                team1_seq, team2_seq, num_seq,\n",
    "                prev_runs=prev_runs,\n",
    "                prev_wickets=prev_wickets,\n",
    "                teacher_forcing_ratio=0.0\n",
    "            )\n",
    "            \n",
    "            loss_runs = criterion(pred_runs, runs)\n",
    "            loss_wickets = criterion(pred_wickets, wickets)\n",
    "            loss = loss_runs + loss_wickets\n",
    "            test_loss += loss.item()\n",
    "            test_r_mae += torch.mean(torch.abs(pred_runs - runs)).item()\n",
    "            test_w_mae += torch.mean(torch.abs(pred_wickets - wickets)).item()\n",
    "            \n",
    "            # Store predictions for classification metrics\n",
    "            all_pred_wickets.append(pred_wickets)\n",
    "            all_actual_wickets.append(wickets)\n",
    "            all_pred_runs.append(pred_runs)\n",
    "            all_actual_runs.append(runs)\n",
    "    \n",
    "    # Calculate classification metrics for the entire epoch\n",
    "    all_pred_wickets = torch.cat(all_pred_wickets)\n",
    "    all_actual_wickets = torch.cat(all_actual_wickets)\n",
    "    w_acc, w_prec, w_rec, w_f1 = calculate_wicket_metrics(all_pred_wickets, all_actual_wickets)\n",
    "\n",
    "    all_pred_runs = torch.cat(all_pred_runs)\n",
    "    all_actual_runs = torch.cat(all_actual_runs)\n",
    "    r_acc, r_prec, r_rec, r_f1 = calculate_runs_metrics(all_pred_runs, all_actual_runs)\n",
    "    \n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "    test_runs_mae.append(test_r_mae / len(test_loader))\n",
    "    test_wickets_mae.append(test_w_mae / len(test_loader))\n",
    "    \n",
    "    test_wicket_accuracy.append(w_acc)\n",
    "    test_wicket_precision.append(w_prec)\n",
    "    test_wicket_recall.append(w_rec)\n",
    "    test_wicket_f1.append(w_f1)\n",
    "    \n",
    "    test_runs_accuracy.append(r_acc)\n",
    "    test_runs_precision.append(r_prec)\n",
    "    test_runs_recall.append(r_rec)\n",
    "    test_runs_f1.append(r_f1)\n",
    "\n",
    "    # Print epoch results with additional metrics\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} (TF ratio: {tf_ratio:.3f}):\")\n",
    "    print(f\"Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}\")\n",
    "    print(f\"Train Runs MAE: {train_runs_mae[-1]:.4f}, Test Runs MAE: {test_runs_mae[-1]:.4f}\")\n",
    "    print(f\"Train Wickets MAE: {train_wickets_mae[-1]:.4f}, Test Wickets MAE: {test_wickets_mae[-1]:.4f}\")\n",
    "    print(f\"Runs Metrics - Train Acc: {train_runs_accuracy[-1]:.4f}, Test Acc: {test_runs_accuracy[-1]:.4f}\")\n",
    "    print(f\"Runs Metrics - Train F1: {train_runs_f1[-1]:.4f}, Test F1: {test_runs_f1[-1]:.4f}\")\n",
    "    print(f\"Wicket Metrics - Train Acc: {train_wicket_accuracy[-1]:.4f}, Test Acc: {test_wicket_accuracy[-1]:.4f}\")\n",
    "    print(f\"Wicket Metrics - Train F1: {train_wicket_f1[-1]:.4f}, Test F1: {test_wicket_f1[-1]:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if test_losses[-1] < best_test_loss:\n",
    "        best_test_loss = test_losses[-1]\n",
    "        torch.save(model.state_dict(), 'best_ipl_model_tf.pth')\n",
    "        print(f\"Best model saved with Test Loss: {best_test_loss:.4f}\")\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        print(f\"CUDA Memory Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")\n",
    "\n",
    "# Continue with your existing plotting code\n",
    "epochs = range(1, num_epochs + 1)\n",
    "# Plot 1: Training vs Testing Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(epochs, test_losses, label='Test Loss', marker='o')\n",
    "plt.title('Training and Testing Loss Over Epochs (with Teacher Forcing)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('loss_over_epochs_tf.png')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plot 2: Training vs Testing Runs MAE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_runs_mae, label='Train Runs MAE', marker='o')\n",
    "plt.plot(epochs, test_runs_mae, label='Test Runs MAE', marker='o')\n",
    "plt.title('Training and Testing Runs MAE Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE (Runs)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('runs_mae_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 3: Training vs Testing Wickets MAE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_wickets_mae, label='Train Wickets MAE', marker='o')\n",
    "plt.plot(epochs, test_wickets_mae, label='Test Wickets MAE', marker='o')\n",
    "plt.title('Training and Testing Wickets MAE Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE (Wickets)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('wickets_mae_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 4: Wicket Classification Metrics - Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_wicket_accuracy, label='Train Accuracy', marker='o')\n",
    "plt.plot(epochs, test_wicket_accuracy, label='Test Accuracy', marker='o')\n",
    "plt.title('Wicket Prediction Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('wicket_accuracy_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 5: Wicket Classification Metrics - F1 Score\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_wicket_f1, label='Train F1', marker='o')\n",
    "plt.plot(epochs, test_wicket_f1, label='Test F1', marker='o')\n",
    "plt.title('Wicket Prediction F1 Score Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('wicket_f1_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_runs_accuracy, label='Train Accuracy', marker='o')\n",
    "plt.plot(epochs, test_runs_accuracy, label='Test Accuracy', marker='o')\n",
    "plt.title('Runs Prediction Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('runs_accuracy_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 7: Runs Classification Metrics - F1 Score\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_runs_f1, label='Train F1', marker='o')\n",
    "plt.plot(epochs, test_runs_f1, label='Test F1', marker='o')\n",
    "plt.title('Runs Prediction F1 Score Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('runs_f1_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 8: Runs Classification Metrics - Precision \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_runs_precision, label='Train Precision', marker='o')\n",
    "plt.plot(epochs, test_runs_precision, label='Test Precision', marker='o')\n",
    "plt.title('Runs Prediction Precision Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('runs_precision_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot 9: Runs Classification Metrics - Recall\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_runs_recall, label='Train Recall', marker='o')\n",
    "plt.plot(epochs, test_runs_recall, label='Test Recall', marker='o')\n",
    "plt.title('Runs Prediction Recall Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('runs_recall_over_epochs.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Plots saved as 'loss_over_epochs.png', 'runs_mae_over_epochs.png', 'wickets_mae_over_epochs.png', 'wicket_accuracy_over_epochs.png', and 'wicket_f1_over_epochs.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8fa96",
   "metadata": {},
   "source": [
    "# Load the best model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6459307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¥ Loading best model for evaluation...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IPLModel(\n",
       "  (team_embedding): Embedding(14, 10)\n",
       "  (lstm): LSTM(25, 32, batch_first=True)\n",
       "  (fc_runs): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (fc_wickets): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"\\nðŸ“¥ Loading best model for evaluation...\")\n",
    "model.load_state_dict(torch.load('best_ipl_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4ce0c",
   "metadata": {},
   "source": [
    "## Simulating the cricket phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def simulate_match(model, team_encoder, scaler, device):\n",
    "#     model.eval()\n",
    "#     valid_teams = list(team_encoder.classes_)\n",
    "#     print(\"\\nAvailable teams:\", valid_teams)\n",
    "\n",
    "#     # 1. Get user input\n",
    "#     batting_team = input(\"Batting team: \").strip()\n",
    "#     bowling_team = input(\"Bowling team: \").strip()\n",
    "#     if batting_team not in valid_teams or bowling_team not in valid_teams:\n",
    "#         print(\"âŒ Invalid team names.\")\n",
    "#         return\n",
    "    \n",
    "#     try:\n",
    "#         innings = int(input(\"Which innings? (1 or 2): \"))\n",
    "#         current_over = int(input(\"Current completed over (e.g., 5): \"))\n",
    "#         current_runs = int(input(\"Current total runs: \"))\n",
    "#         current_wickets = int(input(\"Current total wickets: \"))\n",
    "#         if innings == 2:\n",
    "#             target_score = int(input(\"Target score to win: \"))\n",
    "#         overs_to_simulate = int(input(\"How many overs do you want to simulate? (e.g., 5): \"))\n",
    "#     except ValueError:\n",
    "#         print(\"âŒ Invalid input.\")\n",
    "#         return\n",
    "\n",
    "#     # 2. Initialize state\n",
    "#     total_runs = current_runs\n",
    "#     total_wickets = current_wickets\n",
    "\n",
    "#     team1 = torch.tensor([team_encoder.transform([batting_team])[0]], dtype=torch.long).to(device)\n",
    "#     team2 = torch.tensor([team_encoder.transform([bowling_team])[0]], dtype=torch.long).to(device)\n",
    "\n",
    "#     print(f\"\\nðŸŽ¯ Simulating from over {current_over + 1} to {current_over + overs_to_simulate}...\\n\")\n",
    "\n",
    "#     for i in range(1, overs_to_simulate + 1):\n",
    "#         over_num = current_over + i\n",
    "#         if over_num > 20:\n",
    "#             break  # max 20 overs\n",
    "\n",
    "#         run_rate = total_runs / over_num if over_num > 0 else 0\n",
    "#         target_left = (target_score - total_runs) if innings == 2 else 0\n",
    "#         req_runrate = (target_left / (20 - over_num)) if innings == 2 and (20 - over_num) > 0 else 0\n",
    "#         season_weight = 1  # default neutral\n",
    "\n",
    "#         input_data = scaler.transform([[over_num, run_rate, req_runrate, target_left, season_weight]])\n",
    "#         num_data = torch.tensor(input_data, dtype=torch.float32).to(device)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             pred_runs, pred_wickets = model(team1, team2, num_data)\n",
    "\n",
    "#         pred_runs_val = max(0, pred_runs.item())\n",
    "#         pred_wickets_val = max(0, pred_wickets.item())\n",
    "\n",
    "#         total_runs += pred_runs_val\n",
    "#         total_wickets += round(pred_wickets_val)\n",
    "\n",
    "#         print(f\"ðŸŸ¡ Over {over_num}: +{pred_runs_val:.2f} runs, +{pred_wickets_val:.2f} wickets\")\n",
    "\n",
    "#         if total_wickets >= 10:\n",
    "#             print(\"ðŸ”´ All out!\")\n",
    "#             break\n",
    "\n",
    "#     print(f\"\\nðŸ Final Projected Score: {int(total_runs)}/{min(int(total_wickets), 10)}\")\n",
    "\n",
    "#     if innings == 2:\n",
    "#         if total_runs > target_score:\n",
    "#             print(\"âœ… Projected WIN by\", int(total_runs - target_score), \"runs\")\n",
    "#         elif total_runs < target_score:\n",
    "#             print(\"âŒ Projected LOSS by\", int(target_score - total_runs), \"runs\")\n",
    "#         else:\n",
    "#             print(\"ðŸ¤ Projected TIE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c4e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate_match(model, team_encoder, scaler, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
